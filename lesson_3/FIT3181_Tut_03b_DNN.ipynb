{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  FIT3181: Deep Learning (2021)</span>\n",
    "***\n",
    "*CE/Lecturer:*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
    "*Head TA:*  **Mr Thanh Nguyen** | thanh.nguyen4@monash.edu <br/>\n",
    "*Tutor:* **Dr Van Nguyen**  \\[van.nguyen1@monash.edu \\] | **Mr James Tong** \\[james.tong1@monash.edu\\] | **Dr Mahmoud Mohammad** \\[mahmoud.hossam@monash.edu\\]\n",
    "<br/> <br/>\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">Tutorial 3b: Feed-forward Neural Nets with TensorFlow 2.x</span>\n",
    "**This continues Tutorial 2a and shows you how to implement a feedforward neural network using TF 2.x**:  \n",
    "- ***Inspect how to use keras in TF 2.x to fulfill the task. As you can see later the implementation is much simpler*.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.1 Feedforward Neural Network </span> <span style=\"color:red\">***** (highly important)</span>\n",
    "#### <span style=\"color:#0b486b\"> Tutorial objective </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will consider a fairly realistic deep NN with *three* layers plus the *output* layer. Its architecture will be specified as $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLU) \\rightarrow 26$. This means:\n",
    "- The input size is 16\n",
    "- The first layer has 10 hidden units with 10 ReLU activation functions\n",
    "- The second layer has 20 hidden units with 20 ReLU activation functions\n",
    "- The third layer has 15 hidden units with 15 ReLU activation functions\n",
    "- And the output layer is a logit layer with 26 hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network, for example, can take the `letter` dataset input with $16$ features and with $26$ classes (A-Z). **Our objective in this tutorial is to implement this specific network in `TensorFlow 1.x`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.2 Implementation with TensorFlow 2.x</span> <span style=\"color:red\">***** (highly important)</span>\n",
    "We now shall implement the aforementioned network with the architecture of $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLu) \\rightarrow 26$ in Tensorflow using the dataset `letter`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This letter dataset can be found at [the LIBSVM website](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#letter). Here is the dataset information:\n",
    "-  *The objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet. The character images were based on 20 different fonts and each letter within these 20 fonts was randomly distorted to produce a file of 20,000 unique stimuli. Each stimulus was converted into 16 primitive numerical attributes (statistical moments and edge counts) which were then scaled to fit into a range of integer values from 0 through 15*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical pipeline process of implementing a deep learning model is as follows:\n",
    "\n",
    "1. **Data processing**: \n",
    "    - Load the dataset and split it into train, valid, and test sets.  \n",
    "     \n",
    "2. **Building the model**: \n",
    "    - Build the model using keras layers.\n",
    "     \n",
    "3. **Compiling the model**: \n",
    "    - Compile the model and specify the optimizer, the loss (e.g., cross-entropy loss) you want to optimize, metrics you want to measure. \n",
    "    \n",
    "4. **Training and evaluating**:\n",
    "    - Train the model with a specific training set and validation set in a number of epochs.\n",
    "    - Predict the test set and assess its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">1. Data Processing </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `sklearn` to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape: (15000, 16)\n",
      "y data shape: (15000,)\n",
      "# classes: 26\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20. 21. 22. 23. 24. 25. 26.]\n"
     ]
    }
   ],
   "source": [
    "data_file_name= \"letter_scale.libsvm\"\n",
    "data_file = os.path.abspath(\"./data/\" + data_file_name)\n",
    "X_data, y_data = load_svmlight_file(data_file)\n",
    "X_data= X_data.toarray()\n",
    "print(\"X data shape: {}\".format(X_data.shape))\n",
    "print(\"y data shape: {}\".format(y_data.shape))\n",
    "print(\"# classes: {}\".format(len(np.unique(y_data))))\n",
    "print(np.unique(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `sklearn` to split the dataset into the train, validation, and test sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_valid_test_split(data, target, train_size, test_size):\n",
    "    valid_size = 1 - (train_size + test_size)\n",
    "    X1, X_test, y1, y_test = train_test_split(data, target, test_size = test_size, random_state= 33)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X1, y1, test_size = float(valid_size)/(valid_size+ train_size))\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would like to encode the label in the form of numeric vector. For example, we want to turn $y\\_data=[\"cat\", \"dog\", \"cat\", \"lion\", \"dog\"]$ to $y\\_data=[0,1,0,2,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, in the following segment of code, we use the object `le` as an instance of the class `preprocessing.LabelEncoder()` which supports us to transform categorical labels in `y_data` to a numerical vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25 15 18 ...  0 11 21]\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_data.ravel())\n",
    "y_data= le.transform(y_data)\n",
    "print(y_data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the function defined above to prepare our data for training, validating and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 16) (1500, 16) (1500, 16)\n",
      "(12000,) (1500,) (1500,)\n",
      "lables: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = train_valid_test_split(X_data, y_data, train_size=0.8, test_size=0.1)\n",
    "y_train= y_train.reshape(-1)\n",
    "y_test= y_test.reshape(-1)\n",
    "y_valid= y_valid.reshape(-1)\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)\n",
    "print(\"lables: {}\".format(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size= int(X_train.shape[0])\n",
    "n_features= int(X_train.shape[1])\n",
    "n_classes= len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">2. Build up the model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build up a feedforward neural network with the architecture: $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLu) \\rightarrow 26$ in TensorFlow 2.x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(units=10,  input_shape=(16,), activation='relu'))\n",
    "dnn_model.add(Dense(units=20, activation='relu'))\n",
    "dnn_model.add(Dense(units=15, activation='relu'))\n",
    "dnn_model.add(Dense(units=n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 26)                416       \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model.build()  # computional graph\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x2158d207580>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2158d161340>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2158d161ac0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2158d16ff70>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_21\n"
     ]
    }
   ],
   "source": [
    "hidden1 = dnn_model.layers[0]\n",
    "print(hidden1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init = dnn_model.get_weights()\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">3. Compiling Model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">4. Training and Evaluating </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 847us/step - loss: 2.9410 - accuracy: 0.1268 - val_loss: 2.4020 - val_accuracy: 0.2527\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 0s 639us/step - loss: 1.9143 - accuracy: 0.4239 - val_loss: 1.6807 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 0s 645us/step - loss: 1.5287 - accuracy: 0.5346 - val_loss: 1.4962 - val_accuracy: 0.5540\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 0s 681us/step - loss: 1.3939 - accuracy: 0.5809 - val_loss: 1.3991 - val_accuracy: 0.5793\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 0s 697us/step - loss: 1.3106 - accuracy: 0.6118 - val_loss: 1.3136 - val_accuracy: 0.6207\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 0s 679us/step - loss: 1.2488 - accuracy: 0.6368 - val_loss: 1.2636 - val_accuracy: 0.6380\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 0s 659us/step - loss: 1.1987 - accuracy: 0.6520 - val_loss: 1.2241 - val_accuracy: 0.6307\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 0s 686us/step - loss: 1.1526 - accuracy: 0.6694 - val_loss: 1.1728 - val_accuracy: 0.6580\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 0s 677us/step - loss: 1.1101 - accuracy: 0.6816 - val_loss: 1.1321 - val_accuracy: 0.6687\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 0s 665us/step - loss: 1.0654 - accuracy: 0.6928 - val_loss: 1.0813 - val_accuracy: 0.6967\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 0s 666us/step - loss: 1.0252 - accuracy: 0.7067 - val_loss: 1.0564 - val_accuracy: 0.6940\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 0s 661us/step - loss: 0.9874 - accuracy: 0.7172 - val_loss: 1.0191 - val_accuracy: 0.7093\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 0s 648us/step - loss: 0.9545 - accuracy: 0.7259 - val_loss: 0.9917 - val_accuracy: 0.7147\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 0s 645us/step - loss: 0.9270 - accuracy: 0.7331 - val_loss: 0.9615 - val_accuracy: 0.7227\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 0s 653us/step - loss: 0.9038 - accuracy: 0.7377 - val_loss: 0.9523 - val_accuracy: 0.7200\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 0s 718us/step - loss: 0.8822 - accuracy: 0.7435 - val_loss: 0.9347 - val_accuracy: 0.7273\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 0s 629us/step - loss: 0.8643 - accuracy: 0.7472 - val_loss: 0.9066 - val_accuracy: 0.7327\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 0s 639us/step - loss: 0.8453 - accuracy: 0.7522 - val_loss: 0.8987 - val_accuracy: 0.7307\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 0s 643us/step - loss: 0.8313 - accuracy: 0.7552 - val_loss: 0.8847 - val_accuracy: 0.7320\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 0s 644us/step - loss: 0.8158 - accuracy: 0.7563 - val_loss: 0.8754 - val_accuracy: 0.7367\n"
     ]
    }
   ],
   "source": [
    "history = dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can evaluate the trained model on the test set or any subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 613us/step - loss: 0.8648 - accuracy: 0.7380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8647688627243042, 0.7379999756813049]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(X_test, y_test)  #return loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.34, 0.  , 0.04, 0.  , 0.01, 0.  , 0.01, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.6 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  ], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:10]\n",
    "y_prob = dnn_model.predict(X_new)\n",
    "y_prob[0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect prediction!\n",
      "Corrected predeiction!\n",
      "Incorrect prediction!\n",
      "Incorrect prediction!\n",
      "Corrected predeiction!\n",
      "Corrected predeiction!\n",
      "Incorrect prediction!\n",
      "Corrected predeiction!\n",
      "Corrected predeiction!\n",
      "Corrected predeiction!\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(dnn_model.predict(X_new), axis=-1)\n",
    "for i in range(X_new.shape[0]):\n",
    "    if y_pred[i]==y_test[i]:\n",
    "        print(\"Corrected predeiction!\")\n",
    "    else:\n",
    "        print(\"Incorrect prediction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">5. Visualizing the Performance and Loss Objective Function </span>\n",
    "\n",
    "The `fit()` method returns a History object containing the training parameters (history.params), the list of epochs it went through (history.epoch), and most importantly a dictionary (history.history) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any). If you use this dictionary to create a pandas DataFrame and call its plot() method, you get the learning curves shown in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">6. Playing around with different optimizers</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Evaluating with Nadam\n",
      "\n",
      "47/47 [==============================] - 0s 675us/step - loss: 0.7800 - accuracy: 0.7740\n",
      "The test accuracy is 0.7739999890327454\n",
      "\n",
      "*Evaluating with Adam\n",
      "\n",
      "47/47 [==============================] - 0s 728us/step - loss: 0.7659 - accuracy: 0.7780\n",
      "The test accuracy is 0.777999997138977\n",
      "\n",
      "*Evaluating with Adadelta\n",
      "\n",
      "47/47 [==============================] - 0s 520us/step - loss: 3.2488 - accuracy: 0.0567\n",
      "The test accuracy is 0.05666666850447655\n",
      "\n",
      "*Evaluating with Adagrad\n",
      "\n",
      "47/47 [==============================] - 0s 542us/step - loss: 3.1018 - accuracy: 0.0453\n",
      "The test accuracy is 0.04533333331346512\n",
      "\n",
      "*Evaluating with RMSprop\n",
      "\n",
      "47/47 [==============================] - 0s 525us/step - loss: 0.7996 - accuracy: 0.7747\n",
      "The test accuracy is 0.7746666669845581\n",
      "\n",
      "*Evaluating with SGD\n",
      "\n",
      "47/47 [==============================] - 0s 542us/step - loss: 3.1370 - accuracy: 0.0680\n",
      "The test accuracy is 0.06800000369548798\n",
      "\n",
      "The best accuracy is 0.777999997138977 with Adam\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "optimizer_names = [\"Nadam\", \"Adam\", \"Adadelta\", \"Adagrad\", \"RMSprop\", \"SGD\"]\n",
    "optimizer_list = [keras.optimizers.Nadam(learning_rate=0.001), keras.optimizers.Adam(learning_rate=0.001), keras.optimizers.Adadelta(learning_rate=0.001), \n",
    "                  keras.optimizers.Adagrad(learning_rate=0.001), keras.optimizers.RMSprop(learning_rate=0.001), keras.optimizers.SGD(learning_rate=0.001)]\n",
    "best_acc = 0\n",
    "best_i = -1\n",
    "for i in range(len(optimizer_list)):\n",
    "    dnn_model.set_weights(model_init)\n",
    "    print(\"*Evaluating with {}\\n\".format(str(optimizer_names[i])))\n",
    "    dnn_model.compile(optimizer=optimizer_list[i], loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=30, validation_data=(X_valid, y_valid), verbose=0)\n",
    "    acc = dnn_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"The test accuracy is {}\\n\".format(acc))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_i = i\n",
    "print(\"The best accuracy is {} with {}\".format(best_acc, optimizer_names[best_i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.3 Other Approaches to Build Up Models with TensorFlow 2.x</span> <span style=\"color:red\">*** (relatively important)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> 1. Approach 1: Declaring a class inherited from `tf.keras.Model`</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDNN(tf.keras.Model):\n",
    "    def __init__(self, n_classes= 26):\n",
    "        super(MyDNN, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.dense1 = tf.keras.layers.Dense(units=10, activation= 'relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=20, activation= 'relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(units=15, activation= 'relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(units=self.n_classes, activation= 'softmax')\n",
    "    \n",
    "    def call(self,X): #X is the input, method call specifies how to compute the output from the input X\n",
    "        h = self.dense1(X)\n",
    "        h = self.dense2(h)\n",
    "        h = self.dense3(h)\n",
    "        h = self.dense4(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 3.1304 - accuracy: 0.1138 - val_loss: 2.8232 - val_accuracy: 0.2120\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 0s 804us/step - loss: 2.3696 - accuracy: 0.2861 - val_loss: 2.0825 - val_accuracy: 0.3667\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 0s 744us/step - loss: 1.8543 - accuracy: 0.4449 - val_loss: 1.7824 - val_accuracy: 0.4653\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 0s 714us/step - loss: 1.6351 - accuracy: 0.5091 - val_loss: 1.6309 - val_accuracy: 0.5033\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 0s 827us/step - loss: 1.5050 - accuracy: 0.5527 - val_loss: 1.5228 - val_accuracy: 0.5460\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 0s 800us/step - loss: 1.4055 - accuracy: 0.5797 - val_loss: 1.4388 - val_accuracy: 0.5707\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 0s 779us/step - loss: 1.3194 - accuracy: 0.6140 - val_loss: 1.3489 - val_accuracy: 0.5913\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 0s 752us/step - loss: 1.2477 - accuracy: 0.6438 - val_loss: 1.2943 - val_accuracy: 0.6100\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 0s 752us/step - loss: 1.1990 - accuracy: 0.6559 - val_loss: 1.2509 - val_accuracy: 0.6333\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 0s 784us/step - loss: 1.1588 - accuracy: 0.6689 - val_loss: 1.2200 - val_accuracy: 0.6380\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 0s 757us/step - loss: 1.1294 - accuracy: 0.6766 - val_loss: 1.1810 - val_accuracy: 0.6487\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 0s 752us/step - loss: 1.1023 - accuracy: 0.6823 - val_loss: 1.1585 - val_accuracy: 0.6540\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 0s 699us/step - loss: 1.0792 - accuracy: 0.6898 - val_loss: 1.1375 - val_accuracy: 0.6660\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 0s 810us/step - loss: 1.0572 - accuracy: 0.6950 - val_loss: 1.1077 - val_accuracy: 0.6733\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 0s 827us/step - loss: 1.0389 - accuracy: 0.6992 - val_loss: 1.0950 - val_accuracy: 0.6787\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 0s 763us/step - loss: 1.0189 - accuracy: 0.7023 - val_loss: 1.0763 - val_accuracy: 0.6760\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 0s 709us/step - loss: 1.0019 - accuracy: 0.7118 - val_loss: 1.0670 - val_accuracy: 0.6873\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 0s 811us/step - loss: 0.9869 - accuracy: 0.7153 - val_loss: 1.0606 - val_accuracy: 0.6880\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 0s 763us/step - loss: 0.9713 - accuracy: 0.7193 - val_loss: 1.0321 - val_accuracy: 0.6913\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 0s 800us/step - loss: 0.9584 - accuracy: 0.7201 - val_loss: 1.0155 - val_accuracy: 0.7020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2158af1f580>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydnn = MyDNN(n_classes= 26)\n",
    "mydnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "mydnn.fit(x= X_train, y= y_train, batch_size= 64, epochs= 20, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> 2. Approach 2: Using `tf.keras.Model` Directly</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.layers.Input(shape=(16,)) #declare input layer\n",
    "h = Dense(units=10, activation= 'relu')(X)\n",
    "h = Dense(units=20, activation= 'relu')(h)\n",
    "h = Dense(units=15, activation= 'relu')(h)\n",
    "h = Dense(units=26, activation= 'softmax')(h)\n",
    "dnn_model = tf.keras.Model(inputs= X, outputs=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 3.1804 - accuracy: 0.0918 - val_loss: 2.9488 - val_accuracy: 0.1353\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 0s 677us/step - loss: 2.4060 - accuracy: 0.2946 - val_loss: 2.0105 - val_accuracy: 0.3993\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 0s 752us/step - loss: 1.7515 - accuracy: 0.4821 - val_loss: 1.6569 - val_accuracy: 0.4900\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 0s 706us/step - loss: 1.5155 - accuracy: 0.5473 - val_loss: 1.5152 - val_accuracy: 0.5427\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 0s 795us/step - loss: 1.3982 - accuracy: 0.5833 - val_loss: 1.4151 - val_accuracy: 0.5747\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 0s 736us/step - loss: 1.3214 - accuracy: 0.6096 - val_loss: 1.3531 - val_accuracy: 0.6007\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 0s 736us/step - loss: 1.2639 - accuracy: 0.6308 - val_loss: 1.3006 - val_accuracy: 0.6213\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 0s 677us/step - loss: 1.2159 - accuracy: 0.6499 - val_loss: 1.2624 - val_accuracy: 0.6327\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 0s 741us/step - loss: 1.1752 - accuracy: 0.6626 - val_loss: 1.2411 - val_accuracy: 0.6413\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 0s 768us/step - loss: 1.1403 - accuracy: 0.6737 - val_loss: 1.1879 - val_accuracy: 0.6580\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 0s 667us/step - loss: 1.1083 - accuracy: 0.6837 - val_loss: 1.1521 - val_accuracy: 0.6760\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 0s 683us/step - loss: 1.0784 - accuracy: 0.6908 - val_loss: 1.1130 - val_accuracy: 0.6767\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 0s 765us/step - loss: 1.0511 - accuracy: 0.7000 - val_loss: 1.0968 - val_accuracy: 0.6827\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 0s 797us/step - loss: 1.0278 - accuracy: 0.7063 - val_loss: 1.0681 - val_accuracy: 0.6893\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 0s 757us/step - loss: 1.0024 - accuracy: 0.7141 - val_loss: 1.0458 - val_accuracy: 0.6893\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 0s 725us/step - loss: 0.9820 - accuracy: 0.7176 - val_loss: 1.0266 - val_accuracy: 0.6893\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 0s 762us/step - loss: 0.9613 - accuracy: 0.7236 - val_loss: 1.0038 - val_accuracy: 0.7053\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 0s 757us/step - loss: 0.9425 - accuracy: 0.7297 - val_loss: 0.9933 - val_accuracy: 0.6993\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 0s 795us/step - loss: 0.9267 - accuracy: 0.7318 - val_loss: 0.9718 - val_accuracy: 0.7060\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 0s 719us/step - loss: 0.9113 - accuracy: 0.7337 - val_loss: 0.9624 - val_accuracy: 0.7140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x215820a0bb0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "dnn_model.fit(x= X_train, y= y_train, batch_size= 64, epochs= 20, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> 3. Approach 3: Using Traditional Mini-batch Approach</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#0b486b\">Define a DL model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(units=10,  input_shape=(16,), activation='relu'))\n",
    "dnn_model.add(Dense(units=20, activation='relu'))\n",
    "dnn_model.add(Dense(units=15, activation='relu'))\n",
    "dnn_model.add(Dense(units=n_classes, activation='softmax'))\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#0b486b\">Train model in many epochs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train acc=0.1447, train loss=2.8898 | valid acc=0.1353, valid loss= 2.9032\n",
      "Epoch 2: train acc=0.4305, train loss=1.9913 | valid acc=0.4080, valid loss= 2.0560\n",
      "Epoch 3: train acc=0.5198, train loss=1.6311 | valid acc=0.4880, valid loss= 1.7011\n",
      "Epoch 4: train acc=0.5574, train loss=1.4807 | valid acc=0.5333, valid loss= 1.5509\n",
      "Epoch 5: train acc=0.5881, train loss=1.3897 | valid acc=0.5647, valid loss= 1.4609\n",
      "Epoch 6: train acc=0.6097, train loss=1.3247 | valid acc=0.5847, valid loss= 1.3982\n",
      "Epoch 7: train acc=0.6291, train loss=1.2742 | valid acc=0.6020, valid loss= 1.3510\n",
      "Epoch 8: train acc=0.6398, train loss=1.2330 | valid acc=0.6093, valid loss= 1.3135\n",
      "Epoch 9: train acc=0.6503, train loss=1.1972 | valid acc=0.6200, valid loss= 1.2810\n",
      "Epoch 10: train acc=0.6602, train loss=1.1643 | valid acc=0.6300, valid loss= 1.2515\n",
      "Epoch 11: train acc=0.6689, train loss=1.1326 | valid acc=0.6380, valid loss= 1.2237\n",
      "Epoch 12: train acc=0.6749, train loss=1.1021 | valid acc=0.6433, valid loss= 1.1974\n",
      "Epoch 13: train acc=0.6825, train loss=1.0727 | valid acc=0.6473, valid loss= 1.1725\n",
      "Epoch 14: train acc=0.6888, train loss=1.0441 | valid acc=0.6547, valid loss= 1.1465\n",
      "Epoch 15: train acc=0.6952, train loss=1.0182 | valid acc=0.6620, valid loss= 1.1215\n",
      "Epoch 16: train acc=0.7031, train loss=0.9942 | valid acc=0.6720, valid loss= 1.0979\n",
      "Epoch 17: train acc=0.7085, train loss=0.9723 | valid acc=0.6780, valid loss= 1.0761\n",
      "Epoch 18: train acc=0.7144, train loss=0.9516 | valid acc=0.6840, valid loss= 1.0553\n",
      "Epoch 19: train acc=0.7203, train loss=0.9330 | valid acc=0.6947, valid loss= 1.0365\n",
      "Epoch 20: train acc=0.7257, train loss=0.9163 | valid acc=0.7020, valid loss= 1.0202\n"
     ]
    }
   ],
   "source": [
    "n_epochs =20\n",
    "batch_size = 64\n",
    "for epoch in range(n_epochs):\n",
    "    for idx_start in range(0, X_train.shape[0], batch_size):\n",
    "        idx_end = min(X_train.shape[0], idx_start + batch_size)\n",
    "        X_batch, y_batch = X_train[idx_start:idx_end], y_train[idx_start:idx_end]\n",
    "        train_loss_batch = dnn_model.train_on_batch(X_batch, y_batch)  #return the batch loss\n",
    "        \n",
    "    train_loss, train_acc = dnn_model.evaluate(x= X_train, y= y_train, batch_size= 64, verbose= 0)\n",
    "    valid_loss, valid_acc = dnn_model.evaluate(x= X_valid, y= y_valid, batch_size= 64, verbose= 0)\n",
    "    print('Epoch {}: train acc={:.4f}, train loss={:.4f} | valid acc={:.4f}, valid loss= {:.4f}'.format(epoch + 1, train_acc, train_loss, valid_acc, valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> Additional Exercises </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write your own code to save a trained model to the hard disk and restore this model, then use the restored model to output the prediction result on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write code to tune the learning rate in the list [0.1, 0.01, 0.001, 0.005] for Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Insert new code to the above code to enable outputting to TensorBoard the values of `training loss`, `training accuracy`, `valid loss`, and `valid accuracy` at the end of epochs. You can refer to the code [here](https://www.tensorflow.org/tensorboard/get_started)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write code to do regression on the dataset `cadata` which can be downloaded [here](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html). Note that for a regression problem, you need to use the `L2` loss instead of the `cross-entropy` loss as in a classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:#0b486b\"> <div  style=\"text-align:center\">**THE END**</div> </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.5",
   "language": "python",
   "name": "tf2.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
